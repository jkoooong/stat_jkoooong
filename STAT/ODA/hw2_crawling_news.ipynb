{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "from kornounextractor.noun_extractor import extract\n",
    "import konlpy.tag\n",
    "from collections import Counter \n",
    "from ckonlpy.tag import Twitter\n",
    "from kr_sna import do_kr_sna\n",
    "import nltk\n",
    "import networkx as nx\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기사 내용 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 인터넷 뉴스 기사를 추출하는 함수 생성\n",
    "def get_article(url):\n",
    "    source_code_from_url = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(source_code_from_url, 'lxml', from_encoding='utf-8')\n",
    "    news_title = soup.title.text\n",
    "    publisher = soup.find('meta', attrs={'name':'twitter:creator'}).get('content')\n",
    "    news_content = soup.find('div', attrs = {'id':'articleBodyContents'}).text\n",
    "    news_content = news_content.split('{}')[1].strip()\n",
    "    return news_title, publisher, news_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 조선(cs), 동아(da), 한겨례(hkr), 경향(kh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Chosun.txt','r',encoding='utf8') as f:\n",
    "    full_content_cs=[]\n",
    "    for i in f.readlines():\n",
    "           cs = i.strip()\n",
    "           title_cs, publisher_cs, content_cs = get_article(cs)\n",
    "           filtered_content_cs = re.sub(r'[^\\s\\d\\w\\.\\?\\!\\,]',' ',content_cs)\n",
    "           filtered_content_cs = filtered_content_cs.replace(\"양 회장\",\"양진호\").replace(\"양회장\",\"양진호\").replace(\"회장\",\"양진호\").replace(\"양씨\",\"양진호\")\n",
    "           full_content_cs.append(filtered_content_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Donga.txt','r',encoding='utf8') as f:\n",
    "    full_content_da=[]\n",
    "    for i in f.readlines():\n",
    "           da = i.strip()\n",
    "           title_da, publisher_da, content_da = get_article(da)\n",
    "           filtered_content_da = re.sub(r'[^\\s\\d\\w\\.\\?\\!\\,]',' ',content_da)\n",
    "           filtered_content_da = filtered_content_da.replace(\"양 회장\",\"양진호\").replace(\"양 씨\",\"양진호\").replace(\"양회장\",\"양진호\").replace(\"회장\",\"양진호\").replace(\"양씨\",\"양진호\")\n",
    "           full_content_da.append(filtered_content_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Hankyoreh.txt','r',encoding='utf8') as f:\n",
    "    full_content_hkr=[]\n",
    "    for i in f.readlines():\n",
    "           hkr = i.strip()\n",
    "           title_hkr, publisher_hkr, content_hkr = get_article(hkr)\n",
    "           filtered_content_hkr = re.sub(r'[^\\s\\d\\w\\.\\?\\!\\,]',' ',content_hkr)\n",
    "           filtered_content_hkr = filtered_content_hkr.replace(\"양 회장\",\"양진호\").replace(\"양회장\",\"양진호\").replace(\"회장\",\"양진호\").replace(\"양씨\",\"양진호\").replace(\"헤비 업로더\",\"헤비업로더\")\n",
    "           full_content_hkr.append(filtered_content_hkr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Kyunghyang.txt','r',encoding='utf8') as f:\n",
    "    full_content_kh=[]\n",
    "    for i in f.readlines():\n",
    "           kh = i.strip()\n",
    "           title_kh, publisher_kh, content_kh = get_article(kh)\n",
    "           filtered_content_kh = re.sub(r'[^\\s\\d\\w\\.\\?\\!\\,]',' ',content_kh)\n",
    "           filtered_content_kh = filtered_content_kh.replace(\"양 회장\",\"양진호\").replace(\"양회장\",\"양진호\").replace(\"회장\",\"양진호\").replace(\"양씨\",\"양진호\")\n",
    "           full_content_kh.append(filtered_content_kh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 단어 빈도 분석_명사, 형용사, 동사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 빈도분석을 위한 함수 생성_명사\n",
    "def count_noun(text , n = None):\n",
    "    ## 사용자 지정 사전 등록 kornounextractor 사용\n",
    "    with open('dic.txt', 'w', encoding='utf8') as f:\n",
    "        f.write('헤비업로더'+'\\tNNG\\n')\n",
    "        for word in sorted(extract(text, freq=1.0)):\n",
    "            if word == '갑지':\n",
    "                word ='갑질'\n",
    "            else:\n",
    "                f.write(word+'\\tNNG\\n')   \n",
    "                \n",
    "    komoran = konlpy.tag.Komoran(userdic='dic.txt')\n",
    "    \n",
    "    ## 불용어 사전을 등록 후 불용어 제거\n",
    "    stopwords = ['조선일보','전효진','김우영','기자','뉴스타파','캡처','싸이월드','이날','조선닷컴','바로가기','구독신청하기',\n",
    "                 'Copyrights','무단','전재','재배포','금지','수원','권상은','성남','윤민혁','박성우','chosunbiz','.com',\n",
    "                 'chosun','young','동아일보','donga','한겨레','경향신문','www','khan','.co','.kr','신문구독','아이폰XS',\n",
    "                 '라고','공식 페이스북','hani','무료만화','구독','무단전재']\n",
    "\n",
    "    ### 명사 추출\n",
    "    Nouns = komoran.nouns(text)\n",
    "    final_nouns = Nouns.copy()\n",
    "    unique_nouns = set(Nouns)\n",
    "    for word in unique_nouns:\n",
    "    ### 1음절 단어와 불용어 제거하기\n",
    "        if len(word) == 1:\n",
    "            while word in final_nouns:\n",
    "                  final_nouns.remove(word)\n",
    "        if word in stopwords:\n",
    "            while word in final_nouns:\n",
    "                  final_nouns.remove(word)\n",
    "    ### 빈도수 count\n",
    "    c_noun = Counter(final_nouns) \n",
    "    if n == None:\n",
    "        return print(c_noun.most_common(len(c_noun)))\n",
    "    else:\n",
    "        return print(c_noun.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###빈도분석을 위한 함수 생성_형용사, 동사\n",
    "def count_av(text , n = None):\n",
    "    ## ckonlpy를 이용\n",
    "    twitter = Twitter()\n",
    "\n",
    "    twitter.add_dictionary(\"있다\",\"Verb\")\n",
    "    twitter.add_dictionary(\"없다\",\"Verb\")\n",
    "    twitter.add_dictionary(\"있었다\",\"Verb\")\n",
    "    twitter.add_dictionary(\"갑질\",\"Noun\")\n",
    "    \n",
    "    ## 포스 태깅\n",
    "    twitter_morphs = twitter.pos(text)\n",
    "    \n",
    "    final_adj = []\n",
    "    final_verb = []\n",
    "    for word, pos in twitter_morphs: \n",
    "        if pos == 'Adjective':\n",
    "            final_adj.append(word)\n",
    "        elif pos == 'Verb':\n",
    "            final_verb.append(word)\n",
    "    \n",
    "    ### 빈도수 count    \n",
    "    c_adj = Counter(final_adj)\n",
    "    print(c_adj.most_common(n))\n",
    "    \n",
    "    c_verb = Counter(final_verb)\n",
    "    print(c_verb.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('양진호', 74), ('폭행', 31), ('위디스크', 30), ('직원', 22), ('경찰', 19), ('위반', 15), ('영상', 14), ('한국미래기술', 13), ('혐의', 13), ('파일노리', 12)]\n",
      "[('양진호', 79), ('직원', 32), ('폭행', 26), ('위디스크', 19), ('교수', 18), ('사무실', 14), ('영상', 13), ('압수수색', 12), ('혐의', 11), ('한국미래기술', 10)]\n",
      "[('웹하드', 57), ('업체', 52), ('양진호', 41), ('필터링', 31), ('불법', 23), ('직원', 20), ('영상물', 19), ('위디스크', 19), ('유통', 17), ('폭행', 16)]\n",
      "[('양진호', 34), ('직원', 30), ('폭행', 21), ('상사', 17), ('폭언', 15), ('처벌', 14), ('근로기준법', 14), ('직장 내 괴롭힘', 11), ('직장', 10), ('사용자', 9)]\n"
     ]
    }
   ],
   "source": [
    "count_noun(str(full_content_cs),10)\n",
    "count_noun(str(full_content_da),10)\n",
    "count_noun(str(full_content_hkr),10)\n",
    "count_noun(str(full_content_kh),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('있는', 9), ('같은', 3), ('선한', 3), ('입니다', 1), ('당했던', 1), ('인해', 1), ('좋겠다', 1), ('빠르면', 1), ('굳게', 1), ('검으', 1)]\n",
      "[('했다', 24), ('있다', 14), ('할', 11), ('하는', 11), ('된', 10), ('알려졌다', 6), ('는', 6), ('하기', 6), ('되는', 5), ('들', 4)]\n",
      "[('있는', 12), ('같은', 5), ('많다', 3), ('강한', 2), ('좋겠다', 2), ('그런', 2), ('당했다는', 1), ('없는', 1), ('이러한', 1), ('인해', 1)]\n",
      "[('했다', 57), ('들', 11), ('했다고', 10), ('된', 6), ('와', 6), ('할', 6), ('있다', 6), ('한다', 6), ('밝혔다', 5), ('한', 5)]\n",
      "[('있는', 12), ('같은', 5), ('이런', 5), ('있', 3), ('없는', 3), ('어떤', 2), ('선한', 2), ('많은', 2), ('있지', 1), ('있었', 1)]\n",
      "[('했다', 28), ('있다', 20), ('한다', 12), ('된', 10), ('되는', 10), ('하는', 10), ('할', 9), ('는', 9), ('들', 7), ('한', 7)]\n",
      "[('있는', 8), ('같은', 5), ('있', 4), ('아닌', 3), ('있을', 2), ('많다', 2), ('있고', 2), ('어렵다', 2), ('안되면', 2), ('부끄러운', 1)]\n",
      "[('했다', 26), ('할', 21), ('있다', 20), ('는', 18), ('하는', 15), ('없다', 12), ('한다', 8), ('가', 7), ('한', 7), ('된', 7)]\n"
     ]
    }
   ],
   "source": [
    "count_av(str(full_content_cs),10)\n",
    "count_av(str(full_content_da),10)\n",
    "count_av(str(full_content_hkr),10)\n",
    "count_av(str(full_content_kh),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 네트워크 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Semantic network analysis\n",
    "def get_words_list(counter_list):\n",
    "    words = []\n",
    "    for word, count in counter_list:\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "def get_sentences(content):\n",
    "    sentences = re.split(r'[\\.\\?\\!]\\s+', content)\n",
    "    return sentences\n",
    "\n",
    "def add_ties(g, sentence, komoran):\n",
    "\n",
    "#각 문장에 대해서, 각 문장에서 함께 사용되는 단어들 사이에 관계 형성하기\n",
    "\n",
    "    NN_words = komoran.nouns(sentence)\n",
    "        \n",
    "    selected_words =[]\n",
    "    for noun in set(NN_words):\n",
    "        if noun in list(g.nodes()):\n",
    "            selected_words.append(noun)\n",
    "\n",
    "    for pair in list(itertools.combinations(list(selected_words), 2)):\n",
    "        if pair[0] == pair[1]:\n",
    "            continue\n",
    "        if pair in g.edges(): \n",
    "            g[pair[0]][pair[1]]['weight'] += 1\n",
    "            \n",
    "        else:\n",
    "            g.add_edge(pair[0], pair[1], weight=1 )\n",
    "    \n",
    "    return g\n",
    "\n",
    "def form_network(g, document, komoran):\n",
    "#원본 데이터와 가장 많이 출현하는 명사 단어 x개를 사용해서 그 단어들 사이의 관계 형성하기\n",
    "    for sentence in document:\n",
    "        g = add_ties(g, sentence, komoran)\n",
    "        \n",
    "    return g\n",
    "\n",
    "def do_kr_sna(text, final_nouns, stopwords, fre=2, num=20):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    with open('dic.txt', 'w', encoding='utf8') as f:\n",
    "        for word in sorted(extract(text, freq=fre)):\n",
    "            f.write(word+'\\tNNG\\n')\n",
    "    \n",
    "    komoran = konlpy.tag.Komoran(userdic='dic.txt')\n",
    "    \n",
    "    Nouns = komoran.nouns(text)\n",
    "    \n",
    "    #------------------------------------------------\n",
    "    # 단어 빈도 파악하기 (Frequency analysis)\n",
    "    c = Counter(final_nouns)\n",
    "    list_of_words = get_words_list(c.most_common(num))\n",
    "\n",
    "    # 원본 텍스트 데이터를 문장으로 쪼개기\n",
    "    # in order to find ties between words, we first need to split the article content into sentences\n",
    "    text1 = re.sub(r'[^\\.\\?\\!\\s\\w\\d]', ' ', text.replace('\\n', ' '))\n",
    "    text2 = re.sub(r'([\\.\\?\\!])',r'\\1 ', text1)\n",
    "    article_sentences = get_sentences(text2)\n",
    "    \n",
    "    # 가장 많이 출현하는 num개의 명사 단어들에 대해서 네트워크 생성하기\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(list_of_words)\n",
    "    G = form_network(G, article_sentences, komoran)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_g(text):\n",
    "    \n",
    "    with open('dic.txt', 'w', encoding='utf8') as f:\n",
    "        f.write('헤비업로더'+'\\tNNG\\n')\n",
    "        for word in sorted(extract(text, freq=1.0)):\n",
    "            if word == '갑지':\n",
    "                word ='갑질'\n",
    "            else:\n",
    "                f.write(word+'\\tNNG\\n')    \n",
    "                \n",
    "    komoran = konlpy.tag.Komoran(userdic='dic.txt')\n",
    "    \n",
    "    ## 불용어 사전을 등록 후 불용어 제거\n",
    "    stopwords = ['조선일보','전효진','김우영','기자','뉴스타파','캡처','싸이월드','이날','조선닷컴','바로가기','구독신청하기',\n",
    "                 'Copyrights','무단','전재','재배포','금지','수원','권상은','성남','윤민혁','박성우','chosunbiz','.com',\n",
    "                 'chosun','young','동아일보','donga','한겨레','경향신문','www','khan','.co','.kr','신문구독','아이폰XS',\n",
    "                 '라고','공식 페이스북','hani','무료만화','구독','무단전재']\n",
    "\n",
    "    ### 명사 추출\n",
    "    Nouns = komoran.nouns(text)\n",
    "    final_nouns = Nouns.copy()\n",
    "    unique_nouns = set(Nouns)\n",
    "    for word in unique_nouns:\n",
    "    ### 1음절 단어와 불용어 제거하기\n",
    "        if len(word) == 1:\n",
    "            while word in final_nouns:\n",
    "                  final_nouns.remove(word)\n",
    "        if word in stopwords:\n",
    "            while word in final_nouns:\n",
    "                  final_nouns.remove(word)\n",
    "\n",
    "                \n",
    "    g = do_kr_sna(text, final_nouns, stopwords, num=20)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_cs = out_g(str(full_content_cs))\n",
    "g_da = out_g(str(full_content_da))\n",
    "g_hkr = out_g(str(full_content_hkr)) \n",
    "g_kh = out_g(str(full_content_kh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({'피해자': {'weight': 4}, '폭행': {'weight': 25}, '경찰': {'weight': 14}, '직원': {'weight': 15}, '한국미래기술': {'weight': 11}, '웹하드': {'weight': 6}, '위디스크': {'weight': 21}, '업체': {'weight': 6}, '불법': {'weight': 4}, '영상': {'weight': 7}, '사무실': {'weight': 10}, '2015년 4월': {'weight': 7}, '공개': {'weight': 5}, '위반': {'weight': 6}, '혐의': {'weight': 9}, '파일노리': {'weight': 7}, '음란물': {'weight': 4}, '유통': {'weight': 3}, '포르노': {'weight': 4}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_cs['양진호']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({'직원': {'weight': 14}, '폭행': {'weight': 21}, '한국미래기술': {'weight': 9}, '웹하드': {'weight': 3}, '위디스크': {'weight': 11}, '영상': {'weight': 9}, '불법': {'weight': 5}, '자신': {'weight': 7}, '조사': {'weight': 5}, '사무실': {'weight': 8}, '경찰': {'weight': 8}, '압수수색': {'weight': 9}, '자택': {'weight': 6}, '혐의': {'weight': 10}, '수사': {'weight': 6}, '강요': {'weight': 5}, '위반': {'weight': 4}, '교수': {'weight': 12}, '페이스북': {'weight': 3}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_da['양진호']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({'필터링': {'weight': 5}, '위디스크': {'weight': 9}, '음란물': {'weight': 3}, '사실': {'weight': 3}, '파일노리': {'weight': 7}, '불법': {'weight': 8}, '웹하드': {'weight': 6}, '유통': {'weight': 7}, '업체': {'weight': 6}, '영상물': {'weight': 5}, '직원': {'weight': 8}, '경찰': {'weight': 7}, '폭행': {'weight': 12}, '피해자': {'weight': 5}, '피해': {'weight': 2}, '영상': {'weight': 4}, '수사': {'weight': 4}, '카르테': {'weight': 2}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_hkr['양진호']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({'직원': {'weight': 10}, '한국미래기술': {'weight': 6}, '갑지': {'weight': 4}, '공개': {'weight': 6}, '폭행': {'weight': 9}, '직장갑질119': {'weight': 6}, '직장 내 괴롭힘': {'weight': 4}, '직장': {'weight': 2}, '괴롭힘': {'weight': 2}, '피해자': {'weight': 3}, '근로기준법': {'weight': 3}, '처벌': {'weight': 3}, '폭언': {'weight': 3}, '회사': {'weight': 5}, '상사': {'weight': 1}, '사용자': {'weight': 1}, '경찰': {'weight': 4}, '페이스북': {'weight': 2}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_kh['양진호']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
